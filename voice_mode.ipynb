{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voice_mode.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF6uijIa-Bz-",
        "colab_type": "text"
      },
      "source": [
        "##**Importing the modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWxV6B2Pu1zI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout, Activation\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras import regularizers\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile\n",
        "import sys\n",
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import json\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSTJQcX2-Xz1",
        "colab_type": "text"
      },
      "source": [
        "## Loading dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZjY3RAKg39o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/gdrive')\n",
        "!cp \"/gdrive/My Drive/aud.zip\" \"/aud.zip\"\n",
        "!unzip /aud.zip -d /\n",
        "!clear\n",
        "!sudo mkdir /data\n",
        "!cp /aud/* /data/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7Muy2f3-gf-",
        "colab_type": "text"
      },
      "source": [
        "## Setting path for  dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5DJIn76-mDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = '/data/'  #path here\n",
        "mylist= os.listdir(path)\n",
        "type(mylist)\n",
        "mylist[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbKtVBOT-6Oy",
        "colab_type": "text"
      },
      "source": [
        "## Setting labels to data points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqgOmGOD8mYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feeling_list=[]\n",
        "for item in mylist:\n",
        "    if item[1:3]=='Ne':\n",
        "        feeling_list.append(1)\n",
        "    elif item[1:3]=='Sa':\n",
        "        feeling_list.append(2)\n",
        "    elif item[1:3]=='Su':\n",
        "        feeling_list.append(3)\n",
        "    elif item[1:3]=='Fe':\n",
        "        feeling_list.append(4)\n",
        "    elif item[1:3]=='An':\n",
        "        feeling_list.append(5)\n",
        "    elif item[1:3]=='Di':\n",
        "        feeling_list.append(6)\n",
        "    elif item[1:3]=='Ha':\n",
        "        feeling_list.append(7)\n",
        "\n",
        "labels = pd.DataFrame(feeling_list)\n",
        "labels[-3:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeP9b_tc_Bxl",
        "colab_type": "text"
      },
      "source": [
        "## Extraction of features using libROSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "992C3M6C_5aC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(columns=['feature'])\n",
        "bookmark=0\n",
        "for y in mylist:\n",
        "  X, sample_rate = librosa.load('/data/'+ y, res_type='kaiser_fast',duration=None ,sr=None,offset=0.0)\n",
        "  sample_rate = np.array(sample_rate)\n",
        "  mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=18), axis=0)\n",
        "  feature = mfccs\n",
        "  #rms=np.mean(librosa.feature.rmse(y=None, S=sample_rate, frame_length=1024, hop_length=256, center=True, pad_mode='reflect'),axis=0)  #extra feature\n",
        "  #feature1=rms\n",
        "  #ffeature= np.concatenate((feature, feature1), axis=None)  #adding up different features to dataframe\n",
        "  df.loc[bookmark] =[feature]\n",
        "  \n",
        "  bookmark=bookmark+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF9oz-2X_WRz",
        "colab_type": "text"
      },
      "source": [
        "## Processing the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q41GpwRP9JIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[:]\n",
        "df3 = pd.DataFrame(df['feature'].values.tolist())\n",
        "test=df3\n",
        "newdf = pd.concat([df3,labels], axis=1)\n",
        "rnewdf = newdf.rename(index=str, columns={\"0\": \"label\"})\n",
        "rnewdf = shuffle(newdf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVwz-iUX_Vfe",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BniuaGlf9JQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnewdf[:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kes6qJb9yih",
        "colab_type": "code",
        "outputId": "11a32509-d361-4fd9-80b2-a1daa0a287eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "rnewdf=rnewdf.fillna(0)\n",
        "rnewdf.size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "253936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOtXtCf-_zVT",
        "colab_type": "text"
      },
      "source": [
        "## Setting dimesions for LSTM and encoding the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD284VFq9yse",
        "colab_type": "code",
        "outputId": "f3fb878e-c6e8-478b-baa8-ec47a6bc248b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "train = rnewdf\n",
        "\n",
        "trainfeatures = train.iloc[:, :-1]\n",
        "trainlabel = test.iloc[:,-2:]\n",
        "\n",
        "\n",
        "X_train = np.array(trainfeatures)\n",
        "y_train = np.array(feeling_list)\n",
        "\n",
        "y_train = y_train.reshape((538,1))\n",
        "\n",
        "lb = LabelEncoder()\n",
        "\n",
        "y_train = np_utils.to_categorical(lb.fit_transform(y_train))\n",
        "\n",
        "YY=y_train\n",
        "XX =np.expand_dims(X_train, axis=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Br47Jnv_7Lf",
        "colab_type": "text"
      },
      "source": [
        "## Checking input shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbf7u4V09y6V",
        "colab_type": "code",
        "outputId": "420c96ee-7a1a-4d66-99d4-25128fcabdaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "XX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(538, 471, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23AJ8doC_jGG",
        "colab_type": "code",
        "outputId": "056476ff-2751-4bb9-ff26-127e2440c5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "YY.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(538, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBMjDDiH__i6",
        "colab_type": "text"
      },
      "source": [
        "## Splitting the data points for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTvXRVMC9yn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(XX,YY, test_size = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFFVBAvIAHUX",
        "colab_type": "text"
      },
      "source": [
        "## Model creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9FJd7axOdZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX=XX\n",
        "trainy=YY\n",
        "#trainX= X_train\n",
        "#trainy= Y_train\n",
        "#testX= X_test\n",
        "#testy= Y_test\n",
        "\n",
        "n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "model = Sequential()\n",
        "model.add(LSTM(230, input_shape=(None, n_features)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(230, activation='relu'))\n",
        "model.add(Dense(230, activation='relu'))\n",
        "model.add(Dense(n_outputs, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6_HcmGfANYL",
        "colab_type": "text"
      },
      "source": [
        "## Optimizers and Compilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uah49J04zB2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "#opt = keras.optimizers.Adam(lr=0.001, beta_1=0.99, beta_2=0.99, epsilon=None, decay=0, amsgrad=False)\n",
        "#opt = keras.optimizers.SGD(lr=0.001, momentum=0.0, decay=1e-6, nesterov=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtsijJetAUlJ",
        "colab_type": "text"
      },
      "source": [
        "## Training and Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0GqtvwOOgR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "verbose = 1\n",
        "epochs = 250\n",
        "model.fit(trainX, trainy, epochs=epochs, verbose=verbose)\n",
        "#score, accuracy = model.evaluate(testX, testy, verbose=verbose)\n",
        "#print(\"Test Score: \",score,\"   Test Accuracy: \",accuracy)\n",
        "#print(accuracy)    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NsAOkYCAdzI",
        "colab_type": "text"
      },
      "source": [
        "# **Saving the model as JSON and weights as HD5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KnSSFIwO35S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'mk1_final.h5'\n",
        "save_dir = os.path.join(os.getcwd(), '/saved_models')\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "  os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(\"mk1_final.json\", \"w\") as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZeDIEBTAxyp",
        "colab_type": "text"
      },
      "source": [
        "## **Loading up the model and weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWimKLUakdpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loading json and creating model\n",
        "from keras.models import model_from_json\n",
        "json_file = open('mk1.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(\"/saved_models/mk1.h5\")\n",
        "print(\"Loaded model from disk\")\n",
        " \n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3l1nZT9A-X3",
        "colab_type": "text"
      },
      "source": [
        "## **Testing model on test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xc6q54plJkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"## Predicting emotions on the test data\"\"\"\n",
        "\n",
        "preds = loaded_model.predict(X_test, \n",
        "                         batch_size=32, \n",
        "                         verbose=1)\n",
        "\n",
        "preds\n",
        "\n",
        "preds1=preds.argmax(axis=1)\n",
        "\n",
        "preds1\n",
        "\n",
        "abc = preds1.astype(int).flatten()\n",
        "\n",
        "predictions = (lb.inverse_transform((abc)))\n",
        "\n",
        "preddf = pd.DataFrame({'predictedvalues': predictions})\n",
        "preddf[:10]\n",
        "\n",
        "actual=Y_test.argmax(axis=1)\n",
        "abc123 = actual.astype(int).flatten()\n",
        "actualvalues = (lb.inverse_transform((abc123)))\n",
        "\n",
        "actualdf = pd.DataFrame({'actualvalues': actualvalues})\n",
        "actualdf[:10]\n",
        "\n",
        "finaldf = actualdf.join(preddf)\n",
        "\n",
        "\"\"\"## Actual v/s Predicted emotions\"\"\"\n",
        "finaldf[:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGWf0wxNBOiP",
        "colab_type": "text"
      },
      "source": [
        "# **Testing on external input**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dm970kzolRB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import glob \n",
        "\n",
        "#livedf= pd.DataFrame(columns=['feature'])\n",
        "X, sample_rate = librosa.load('/4Su1.WAV', res_type='kaiser_fast',duration=None,sr=22050,offset=0.0)\n",
        "sample_rate = np.array(sample_rate)\n",
        "mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=13),axis=0)\n",
        "featurelive = mfccs\n",
        "livedf2 = featurelive\n",
        "livedf2.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z752dYbhrmsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "livedf2= pd.DataFrame(data=livedf2)\n",
        "\n",
        "livedf2 = livedf2.stack().to_frame().T\n",
        "\n",
        "x,y = livedf2.shape\n",
        "\n",
        "twodim= np.expand_dims(livedf2, axis=2)\n",
        "\n",
        "livepreds = loaded_model.predict(twodim)\n",
        "\n",
        "\n",
        "livepreds\n",
        "\n",
        "livepreds1=livepreds.argmax(axis=1)\n",
        "\n",
        "liveabc = livepreds1.astype(int).flatten()\n",
        "\n",
        "livepredictions = (lb.inverse_transform((liveabc)))\n",
        "livepredictions\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}